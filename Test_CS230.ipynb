{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from scipy.io import loadmat\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding in .tfRecords from .Mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_1.tfrecords',\n",
       " 'train_2.tfrecords',\n",
       " 'train_3.tfrecords',\n",
       " 'train_4.tfrecords',\n",
       " 'train_5.tfrecords',\n",
       " 'train_6.tfrecords',\n",
       " 'train_7.tfrecords',\n",
       " 'train_8.tfrecords']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_addrs = [\"MatlabData/trial_\"+str(i+1)+\".mat\" for i in range(7361) ]\n",
    "train_addrs[0:5]\n",
    "\n",
    "size_batch_in_memory = 1000\n",
    "num_batches = len(train_addrs)//size_batch_in_memory +((len(train_addrs)%size_batch_in_memory)>0)\n",
    "\n",
    "#Addresses to save the TFRecords file\n",
    "train_filename = [\"train_\"+str(i+1)+\".tfrecords\" for i in range(num_batches)]\n",
    "train_filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def from_sparse_matrix_to_feature(features, mapping_number,name=\"default\"):\n",
    "    sparse_array = features[mapping_number]\n",
    "    index_x, index_y, values = sparse.find(sparse_array)\n",
    "    shape = sparse_array.shape\n",
    "    \n",
    "    feature = {    name+'_x': _int64_feature(index_x), \n",
    "                   name+'_y': _int64_feature(index_y),\n",
    "                   name+'_values': _float_feature(values),\n",
    "                   name+'_shape':  _int64_feature(shape)\n",
    "              }\n",
    "    return feature \n",
    "\n",
    "def from_int_matrix_to_feature(features, mapping_number, name=\"default\"):\n",
    "    return {name: _int64_feature(np.array(features[mapping_number].flatten()))}\n",
    "\n",
    "def from_float_matrix_to_feature(features, mapping_number, name=\"default\"):\n",
    "    return {name: _float_feature(np.array(features[mapping_number].flatten()))}\n",
    "\n",
    "def from_string_matrix_to_feature(features, mapping_number, name=\"default\"):\n",
    "    return {name: _bytes_feature(np.array(features[mapping_number].flatten(), dtype='str'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('mapping_Mat_Python.npy', map_name_to_type_and_position) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_name_to_type_and_position = np.load('mapping_Mat_Python.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate on the number of files\n",
    "for j in range(num_batches):\n",
    "    # open the TFRecords file\n",
    "    writer = tf.python_io.TFRecordWriter(train_filename[j]) \n",
    "    \n",
    "    for i in range(size_batch_in_memory):\n",
    "        \n",
    "        #Case where no file left\n",
    "        if j*size_batch_in_memory+i>=len(train_addrs):\n",
    "            writer.close()\n",
    "            break\n",
    "            \n",
    "        # print how many examples are saved every 100 images\n",
    "        if not i % 100:\n",
    "            print 'Train data: {}/{}'.format(j*size_batch+i, len(train_addrs))\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        # Load the the .mat file \n",
    "        mat = loadmat(train_addrs[j*size_batch+i])\n",
    "        features = list(mat['structarr'][0,0])\n",
    "        \n",
    "        # Convert the features \n",
    "        feature = {}\n",
    "        for k in map_name_to_type_and_position:\n",
    "            map_number, map_type = map_name_to_type_and_position[k]\n",
    "            if map_type == int:\n",
    "                feature.update(from_int_matrix_to_feature(features, map_number, name=k))\n",
    "            if map_type == float:\n",
    "                feature.update(from_float_matrix_to_feature(features, map_number, name=k))\n",
    "            if map_type == 'str':\n",
    "                feature.update(from_string_matrix_to_feature(features, map_number, name=k))\n",
    "            if map_type == 'sparse':\n",
    "                feature.update(from_sparse_matrix_to_feature(features, map_number, name=k))\n",
    "                \n",
    "\n",
    "        # Create an example protocol buffer\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "        # Serialize to string and write on the file\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len_sequence = 2568\n",
    "\n",
    "n_steps = 200\n",
    "n_steps_to_predict = 10\n",
    "n_features_spikeRaster = 96\n",
    "n_dims_output = 3\n",
    "\n",
    "n_inputs = n_features_spikeRaster + n_dims_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "    \n",
    "    features = {\n",
    "                \"handPos\" : tf.VarLenFeature(tf.float32),\n",
    "                'spikeRaster': tf.SparseFeature(index_key=['spikeRaster_x', 'spikeRaster_y'],\n",
    "                                                  value_key='spikeRaster_values',\n",
    "                                                  dtype=tf.float32, size=[n_features_spikeRaster, max_len_sequence]),\n",
    "                \"spikeRaster_shape\": tf.FixedLenFeature([2],tf.int64)               \n",
    "               }\n",
    "    \n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    \n",
    "    # Preprocess spikeRaster => [Time Series n_steps x n_features_spikeRaster]\n",
    "    parsed_features[\"spikeRaster\"] = tf.sparse_slice(parsed_features[\"spikeRaster\"],\n",
    "                                                     [0,0],parsed_features[\"spikeRaster_shape\"])\n",
    "    parsed_features[\"spikeRaster\"] = tf.sparse_tensor_to_dense(parsed_features[\"spikeRaster\"])\n",
    "    spikeRaster = tf.reshape(tf.transpose(parsed_features[\"spikeRaster\"]), [-1,n_features_spikeRaster])\n",
    "    \n",
    "    # Preprocess lengths of sequences = []\n",
    "    seq_length = tf.cast(parsed_features[\"spikeRaster_shape\"][1], tf.int32)\n",
    "        \n",
    "    # Preprocess handPos = [n_steps x 3] => HELPER\n",
    "    handPos = tf.sparse_tensor_to_dense(parsed_features[\"handPos\"])\n",
    "    handPos = tf.transpose(tf.reshape(handPos, [n_dims_output,-1]))\n",
    "    \n",
    "    # Useful features\n",
    "    features = tf.concat([spikeRaster,handPos], axis=1)    \n",
    "    return features\n",
    "\n",
    "def get_slices(x):\n",
    "    num_slices = tf.shape(x, out_type=tf.int64)[0] - n_steps - n_steps_to_predict + 1\n",
    "    return tf.data.Dataset.range(num_slices).map(lambda i: (x[i:i + n_steps] , \n",
    "                                                            x[i+n_steps:i+n_steps+n_steps_to_predict,-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SparseFeature is a complicated feature config and should only be used after careful consideration of VarLenFeature.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "size_batch = 32\n",
    "filenames = [\"Data/train_\"+str(i+1)+\".tfrecords\" for i in range(1)]\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(_parse_function)\n",
    "dataset = dataset.flat_map(get_slices)\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size=10000)\n",
    "dataset = dataset.batch(size_batch)\n",
    "dataset = dataset.repeat(num_epochs)\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "inputs, real_position = iterator.get_next()\n",
    "\n",
    "inputs.set_shape([None,n_steps,n_inputs])\n",
    "real_position.set_shape([None,n_steps_to_predict,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    e1, e2 = sess.run([inputs, real_position])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'IteratorGetNext:0' shape=(?, 200, 99) dtype=float32>,\n",
       " <tf.Tensor 'IteratorGetNext:1' shape=(?, 10, 3) dtype=float32>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, real_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "is_training = tf.placeholder(tf.bool, [])\n",
    "\n",
    "keep_prob = 0.5\n",
    "num_units = 128\n",
    "\n",
    "# Build RNN cell\n",
    "encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "\n",
    "# Run Dynamic RNN\n",
    "# inputs: [batch_size, n_steps, n_inputs]\n",
    "rnn_outputs, _ = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, inputs,\n",
    "    time_major=False,\n",
    "    dtype = tf.float32)\n",
    "\n",
    "# Recover meaningful outputs // Predict 3D positions\n",
    "rnn_outputs = rnn_outputs[:,- n_steps_to_predict:,:]\n",
    "predicted_position = tf.layers.dense(rnn_outputs, 3)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(predictions=predicted_position, labels=real_position)\n",
    "training_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', loss)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 0 epochs: 68937.8828125\n",
      "Loss after 100 iteration: 1532.94726562\n",
      "Loss after 200 iteration: 17520.5253906\n",
      "Loss after 300 iteration: 49794.5820312\n",
      "Loss after 400 iteration: 17232.7265625\n",
      "Loss after 500 iteration: 16982.90625\n",
      "Loss after 600 iteration: 585.482971191\n",
      "Loss after 700 iteration: 16359.5449219\n",
      "Loss after 800 iteration: 228.598861694\n",
      "Loss after 900 iteration: 175.397598267\n",
      "Loss after 1000 iteration: 186.21282959\n",
      "Loss after 1100 iteration: 15859.78125\n",
      "Loss after 1200 iteration: 153.671188354\n",
      "Loss after 1300 iteration: 149.281417847\n",
      "Loss after 1400 iteration: 89.3643722534\n",
      "Loss after 1500 iteration: 53.9564590454\n",
      "Loss after 1600 iteration: 89.3916320801\n",
      "Loss after 1700 iteration: 72.5566253662\n",
      "Loss after 1800 iteration: 109.30480957\n",
      "Loss after 1900 iteration: 96.0612411499\n",
      "Loss after 2000 iteration: 58.0750999451\n",
      "Loss after 2100 iteration: 60.0071792603\n",
      "Loss after 2200 iteration: 56.8306236267\n",
      "Loss after 2300 iteration: 15.4345197678\n",
      "Loss after 2400 iteration: 52.406162262\n",
      "Loss after 2500 iteration: 38.5007476807\n",
      "Loss after 2600 iteration: 50.4968910217\n",
      "Loss after 2700 iteration: 56.222530365\n",
      "Loss after 2800 iteration: 1.93225240707\n",
      "Loss after 2900 iteration: 12.92420578\n",
      "Loss after 3000 iteration: 16.0025215149\n",
      "Loss after 3100 iteration: 6.74761962891\n",
      "Loss after 3200 iteration: 8.21124362946\n",
      "Loss after 3300 iteration: 8.69925117493\n",
      "Loss after 3400 iteration: 30.4817504883\n",
      "Loss after 3500 iteration: 193.354034424\n",
      "Loss after 3600 iteration: 311.211761475\n",
      "Loss after 3700 iteration: 75.3447189331\n",
      "Loss after 3800 iteration: 147.702377319\n",
      "Loss after 3900 iteration: 57.9695892334\n",
      "Loss after 4000 iteration: 35.0227813721\n",
      "Loss after 4100 iteration: 31.1200256348\n",
      "Loss after 4200 iteration: 54.8417549133\n",
      "Loss after 4300 iteration: 40.6544265747\n",
      "Loss after 4400 iteration: 15.6530170441\n",
      "Loss after 4500 iteration: 2.78636908531\n",
      "Loss after 4600 iteration: 29.8141593933\n",
      "Loss after 4700 iteration: 7.80401611328\n",
      "Loss after 4800 iteration: 7.22093200684\n",
      "Loss after 4900 iteration: 5.13663911819\n",
      "Loss after 5000 iteration: 2.34224534035\n",
      "Loss after 5100 iteration: 1.98245489597\n",
      "Loss after 5200 iteration: 2.31427907944\n",
      "Loss after 5300 iteration: 4.09609651566\n",
      "Loss after 5400 iteration: 1.58908104897\n",
      "Loss after 5500 iteration: 2.75060725212\n",
      "Loss after 5600 iteration: 1.39006114006\n",
      "Loss after 5700 iteration: 2.25188755989\n",
      "Loss after 5800 iteration: 0.965305030346\n",
      "Loss after 5900 iteration: 1.04791855812\n",
      "Loss after 6000 iteration: 0.897097885609\n",
      "Loss after 6100 iteration: 0.76886934042\n",
      "Loss after 6200 iteration: 1.59059011936\n",
      "Loss after 6300 iteration: 1.47653245926\n",
      "Loss after 6400 iteration: 2.48971414566\n",
      "Loss after 6500 iteration: 1.89721190929\n",
      "Loss after 6600 iteration: 1.17032074928\n",
      "Loss after 6700 iteration: 1.7620292902\n",
      "Loss after 6800 iteration: 0.977984666824\n",
      "Loss after 6900 iteration: 2.56740832329\n",
      "Loss after 7000 iteration: 0.737458944321\n",
      "Loss after 7100 iteration: 1.03315865993\n",
      "Loss after 7200 iteration: 1.30961155891\n",
      "Loss after 7300 iteration: 0.541589975357\n",
      "Loss after 7400 iteration: 1.4782885313\n",
      "Loss after 7500 iteration: 1.73673963547\n",
      "Loss after 7600 iteration: 1.18000817299\n",
      "Loss after 7700 iteration: 2.08014369011\n",
      "Loss after 7800 iteration: 1.05262255669\n",
      "Loss after 7900 iteration: 24.2659702301\n",
      "Loss after 8000 iteration: 24.6321144104\n",
      "Loss after 8100 iteration: 13.9085664749\n",
      "Loss after 8200 iteration: 23.0145626068\n",
      "Loss after 8300 iteration: 16.7903709412\n",
      "Loss after 8400 iteration: 6.59070062637\n",
      "Loss after 8500 iteration: 12.2570762634\n",
      "Loss after 8600 iteration: 1.35814249516\n",
      "Loss after 8700 iteration: 0.868699789047\n",
      "Loss after 8800 iteration: 1.03383290768\n",
      "Loss after 8900 iteration: 0.813435196877\n",
      "Loss after 9000 iteration: 1.1123303175\n",
      "Loss after 9100 iteration: 1.59564077854\n",
      "Loss after 9200 iteration: 0.722625076771\n",
      "Loss after 9300 iteration: 0.940816283226\n",
      "Loss after 9400 iteration: 0.78086066246\n",
      "Loss after 9500 iteration: 0.883928835392\n",
      "Loss after 9600 iteration: 1.24405419827\n",
      "Loss after 9700 iteration: 1.72346425056\n",
      "Loss after 9800 iteration: 1.59978735447\n",
      "Loss after 9900 iteration: 0.959899008274\n",
      "Loss after 10000 iteration: 1.52039945126\n",
      "Loss after 10100 iteration: 0.99353736639\n",
      "Loss after 10200 iteration: 2.39464783669\n",
      "Loss after 10300 iteration: 1.2657315731\n",
      "Loss after 10400 iteration: 1.6295260191\n",
      "Loss after 10500 iteration: 0.81106621027\n",
      "Loss after 10600 iteration: 0.938167452812\n",
      "Loss after 10700 iteration: 1.63967514038\n",
      "Loss after 10800 iteration: 1.41262972355\n",
      "Loss after 10900 iteration: 0.886563718319\n",
      "Loss after 11000 iteration: 1.70635986328\n",
      "Loss after 11100 iteration: 1.73117792606\n",
      "Loss after 11200 iteration: 0.873280227184\n",
      "Loss after 11300 iteration: 1.12074577808\n",
      "Loss after 11400 iteration: 1.15646374226\n",
      "Loss after 11500 iteration: 0.64792817831\n",
      "Loss after 11600 iteration: 1.0450398922\n",
      "Loss after 11700 iteration: 1.04620671272\n",
      "Loss after 11800 iteration: 1.2319444418\n",
      "Loss after 11900 iteration: 0.279741734266\n",
      "Loss after 12000 iteration: 1.10497462749\n",
      "Loss after 12100 iteration: 0.740470230579\n",
      "Loss after 12200 iteration: 0.937800228596\n",
      "Loss after 12300 iteration: 0.650408327579\n",
      "Loss after 12400 iteration: 1.03285372257\n",
      "Loss after 12500 iteration: 1.39945340157\n",
      "Loss after 12600 iteration: 0.85492670536\n",
      "Loss after 12700 iteration: 1.1765859127\n",
      "Loss after 12800 iteration: 0.758996844292\n",
      "Loss after 12900 iteration: 0.909838616848\n",
      "Loss after 13000 iteration: 1.00019657612\n",
      "Loss after 13100 iteration: 0.838116586208\n",
      "Loss after 13200 iteration: 0.877020537853\n",
      "Loss after 13300 iteration: 0.712683022022\n",
      "Loss after 13400 iteration: 0.506957292557\n",
      "Loss after 13500 iteration: 0.781751513481\n",
      "Loss after 13600 iteration: 0.609309196472\n",
      "Loss after 13700 iteration: 0.371893584728\n",
      "Loss after 13800 iteration: 91950.140625\n",
      "Loss after 13900 iteration: 100379.601562\n",
      "Loss after 14000 iteration: 72911.875\n",
      "Loss after 14100 iteration: 12162.3837891\n",
      "Loss after 14200 iteration: 83033.890625\n",
      "Loss after 14300 iteration: 47390.3125\n",
      "Loss after 14400 iteration: 22877.1914062\n",
      "Loss after 14500 iteration: 23410.7578125\n",
      "Loss after 14600 iteration: 1.3373799324\n",
      "Loss after 14700 iteration: 2.23032331467\n",
      "Loss after 14800 iteration: 1.74894607067\n",
      "Loss after 14900 iteration: 1.65455758572\n",
      "Loss after 15000 iteration: 2.20163321495\n",
      "Loss after 15100 iteration: 1.31567490101\n",
      "Loss after 15200 iteration: 1.1859664917\n",
      "Loss after 15300 iteration: 3.57401823997\n",
      "Loss after 15400 iteration: 14.0384235382\n",
      "Loss after 15500 iteration: 2.81488656998\n",
      "Loss after 15600 iteration: 1.78556168079\n",
      "Loss after 15700 iteration: 1.51741790771\n",
      "Loss after 15800 iteration: 34265.1210938\n",
      "Loss after 15900 iteration: 121142.0\n",
      "Loss after 16000 iteration: 168284.59375\n",
      "Loss after 16100 iteration: 71914.5\n",
      "Loss after 16200 iteration: 70631.2890625\n",
      "Loss after 16300 iteration: 29877.1679688\n",
      "Loss after 16400 iteration: 9868.67089844\n",
      "Loss after 16500 iteration: 9795.73339844\n",
      "Loss after 16600 iteration: 19474.1992188\n",
      "Loss after 16700 iteration: 19308.7714844\n",
      "Loss after 16800 iteration: 19240.6582031\n",
      "Loss after 16900 iteration: 2.74833321571\n",
      "Loss after 17000 iteration: 1.90333485603\n",
      "Loss after 17100 iteration: 2.38697767258\n",
      "Loss after 17200 iteration: 1.57154226303\n",
      "Loss after 17300 iteration: 1.71671450138\n",
      "Loss after 17400 iteration: 3.26811766624\n",
      "Loss after 17500 iteration: 0.619888246059\n",
      "Loss after 17600 iteration: 1.03454267979\n",
      "Loss after 17700 iteration: 45666.9609375\n",
      "Loss after 17800 iteration: 98916.21875\n",
      "Loss after 17900 iteration: 26268.2597656\n",
      "Loss after 18000 iteration: 25701.3398438\n",
      "Loss after 18100 iteration: 75872.765625\n",
      "Loss after 18200 iteration: 33338.3632812\n",
      "Loss after 18300 iteration: 8264.61816406\n",
      "Loss after 18400 iteration: 8192.65039062\n",
      "Loss after 18500 iteration: 16248.2011719\n",
      "Loss after 18600 iteration: 8095.92919922\n",
      "Loss after 18700 iteration: 8071.33496094\n",
      "Loss after 18800 iteration: 8046.60009766\n",
      "Loss after 18900 iteration: 23148.3574219\n",
      "Loss after 19000 iteration: 128585.484375\n",
      "Loss after 19100 iteration: 95043.0\n",
      "Loss after 19200 iteration: 76981.6796875\n",
      "Loss after 19300 iteration: 48360.859375\n",
      "Loss after 19400 iteration: 81632.8828125\n",
      "Loss after 19500 iteration: 22527.2949219\n",
      "Loss after 19600 iteration: 71594.75\n",
      "Loss after 19700 iteration: 83025.09375\n",
      "Loss after 19800 iteration: 62034.7148438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 19900 iteration: 60695.5039062\n",
      "Loss after 20000 iteration: 41887.890625\n",
      "Loss after 20100 iteration: 41301.390625\n",
      "Loss after 20200 iteration: 40937.25\n",
      "Loss after 20300 iteration: 11684.4121094\n",
      "Loss after 20400 iteration: 5784.11865234\n",
      "Loss after 20500 iteration: 1.7737621069\n",
      "Loss after 20600 iteration: 1.34397566319\n",
      "Loss after 20700 iteration: 5740.24902344\n",
      "Loss after 20800 iteration: 1.99288570881\n",
      "Loss after 20900 iteration: 1.47819638252\n",
      "Loss after 21000 iteration: 0.618279159069\n",
      "Loss after 21100 iteration: 72757.6171875\n",
      "Loss after 21200 iteration: 60031.2734375\n",
      "Loss after 21300 iteration: 31606.4023438\n",
      "Loss after 21400 iteration: 31332.1308594\n",
      "Loss after 21500 iteration: 27852.1542969\n",
      "Loss after 21600 iteration: 15930.3105469\n",
      "Loss after 21700 iteration: 15636.6962891\n",
      "Loss after 21800 iteration: 20673.4199219\n",
      "Loss after 21900 iteration: 5074.95947266\n",
      "Loss after 22000 iteration: 38268.859375\n",
      "Loss after 22100 iteration: 57542.5\n",
      "Loss after 22200 iteration: 37222.8632812\n",
      "Loss after 22300 iteration: 42166.7070312\n",
      "Loss after 22400 iteration: 22287.0957031\n",
      "Loss after 22500 iteration: 13190.203125\n",
      "Loss after 22600 iteration: 12641.2832031\n",
      "Loss after 22700 iteration: 3356.27856445\n",
      "Loss after 22800 iteration: 8316.91015625\n",
      "Loss after 22900 iteration: 4143.89794922\n",
      "Loss after 23000 iteration: 1.04428911209\n",
      "Loss after 23100 iteration: 1.45066761971\n",
      "Loss after 23200 iteration: 1.62644422054\n",
      "Loss after 23300 iteration: 1.88623464108\n",
      "Loss after 23400 iteration: 4103.12109375\n",
      "Loss after 23500 iteration: 2.08811020851\n",
      "Loss after 23600 iteration: 0.583917975426\n",
      "Loss after 23700 iteration: 1.10962998867\n",
      "Loss after 23800 iteration: 5.68623447418\n",
      "Loss after 23900 iteration: 2.47290158272\n",
      "Loss after 24000 iteration: 1.97888207436\n",
      "Loss after 24100 iteration: 3.23650360107\n",
      "Loss after 24200 iteration: 0.928656518459\n",
      "Loss after 24300 iteration: 1.39170074463\n",
      "Loss after 24400 iteration: 1.27672064304\n",
      "Loss after 24500 iteration: 0.89369314909\n",
      "Loss after 24600 iteration: 0.900315582752\n",
      "Loss after 24700 iteration: 1.38448262215\n",
      "Loss after 24800 iteration: 0.924343049526\n",
      "Loss after 24900 iteration: 0.917028009892\n",
      "Loss after 25000 iteration: 1.40885078907\n",
      "Loss after 25100 iteration: 18606.9082031\n",
      "Loss after 25200 iteration: 46178.546875\n",
      "Loss after 25300 iteration: 39164.3085938\n",
      "Loss after 25400 iteration: 29633.7714844\n",
      "Loss after 25500 iteration: 26141.4277344\n",
      "Loss after 25600 iteration: 16452.0546875\n",
      "Loss after 25700 iteration: 6259.75195312\n",
      "Loss after 25800 iteration: 9269.12304688\n",
      "Loss after 25900 iteration: 12234.5371094\n",
      "Loss after 26000 iteration: 2.62251734734\n",
      "Loss after 26100 iteration: 3014.96313477\n",
      "Loss after 26200 iteration: 1.52413916588\n",
      "Loss after 26300 iteration: 1.69932579994\n",
      "Loss after 26400 iteration: 0.789472222328\n",
      "Loss after 26500 iteration: 0.561202347279\n",
      "Loss after 26600 iteration: 1.05238652229\n",
      "Loss after 26700 iteration: 0.768767774105\n",
      "Loss after 26800 iteration: 0.857467114925\n",
      "Loss after 26900 iteration: 1.47524321079\n",
      "Loss after 27000 iteration: 2.05792665482\n",
      "Loss after 27100 iteration: 1.17307150364\n",
      "Loss after 27200 iteration: 0.760751366615\n",
      "Loss after 27300 iteration: 0.750342905521\n",
      "Loss after 27400 iteration: 1.55504262447\n",
      "Loss after 27500 iteration: 2.41587519646\n",
      "Loss after 27600 iteration: 1.04633402824\n",
      "Loss after 27700 iteration: 1.10882461071\n",
      "Loss after 27800 iteration: 1.08815038204\n",
      "Loss after 27900 iteration: 0.919486165047\n",
      "Loss after 28000 iteration: 0.908024966717\n",
      "Loss after 28100 iteration: 1.40116429329\n",
      "Loss after 28200 iteration: 1.154971838\n",
      "Loss after 28300 iteration: 1.68360626698\n",
      "Loss after 28400 iteration: 1.05907475948\n",
      "Loss after 28500 iteration: 1.33069121838\n",
      "Loss after 28600 iteration: 11746.6289062\n",
      "Loss after 28700 iteration: 10139.6962891\n",
      "Loss after 28800 iteration: 3271.24365234\n",
      "Loss after 28900 iteration: 2.4136762619\n",
      "Loss after 29000 iteration: 3154.78857422\n",
      "Loss after 29100 iteration: 1.33493494987\n",
      "Loss after 29200 iteration: 1.83753204346\n",
      "Loss after 29300 iteration: 1.59533631802\n",
      "Loss after 29400 iteration: 1.77990829945\n",
      "Loss after 29500 iteration: 0.94416975975\n",
      "Loss after 29600 iteration: 1.01930987835\n",
      "Loss after 29700 iteration: 1.47529101372\n",
      "Loss after 29800 iteration: 0.968829333782\n",
      "Loss after 29900 iteration: 0.998949289322\n",
      "Loss after 30000 iteration: 1.14069497585\n",
      "Loss after 30100 iteration: 1.01129329205\n",
      "Loss after 30200 iteration: 0.993250012398\n",
      "Loss after 30300 iteration: 0.83798968792\n",
      "Loss after 30400 iteration: 2983.20361328\n",
      "Loss after 30500 iteration: 1.06796896458\n",
      "Loss after 30600 iteration: 1.4702590704\n",
      "Loss after 30700 iteration: 1.46106421947\n",
      "Loss after 30800 iteration: 0.790424585342\n",
      "Loss after 30900 iteration: 0.871559262276\n",
      "Loss after 31000 iteration: 0.894860506058\n",
      "Loss after 31100 iteration: 1.32200825214\n",
      "Loss after 31200 iteration: 1.52482116222\n",
      "Loss after 31300 iteration: 0.785387039185\n",
      "Loss after 31400 iteration: 0.647663712502\n",
      "Loss after 31500 iteration: 0.859891891479\n",
      "Loss after 31600 iteration: 1.00339365005\n",
      "Loss after 31700 iteration: 1.42036116123\n",
      "Loss after 31800 iteration: 0.530308902264\n",
      "Loss after 31900 iteration: 0.668633282185\n",
      "Loss after 32000 iteration: 1.30334424973\n",
      "Loss after 32100 iteration: 79.2847137451\n",
      "Loss after 32200 iteration: 11775.515625\n",
      "Loss after 32300 iteration: 2555.53930664\n",
      "Loss after 32400 iteration: 6.11233520508\n",
      "Loss after 32500 iteration: 14.8654870987\n",
      "Loss after 32600 iteration: 25.7608566284\n",
      "Loss after 32700 iteration: 1.897164464\n",
      "Loss after 32800 iteration: 1.91482758522\n",
      "Loss after 32900 iteration: 10.5593004227\n",
      "Loss after 33000 iteration: 2.06626558304\n",
      "Loss after 33100 iteration: 2.32086634636\n",
      "Loss after 33200 iteration: 1.35123026371\n",
      "Loss after 33300 iteration: 1.65374982357\n",
      "Loss after 33400 iteration: 2.08482861519\n",
      "Loss after 33500 iteration: 1.99617052078\n",
      "Loss after 33600 iteration: 1.37641072273\n",
      "Loss after 33700 iteration: 2.45919847488\n",
      "Loss after 33800 iteration: 1.55171477795\n",
      "Loss after 33900 iteration: 1.35734260082\n",
      "Loss after 34000 iteration: 1.60692965984\n",
      "Loss after 34100 iteration: 1.95365798473\n",
      "Loss after 34200 iteration: 1.22972536087\n",
      "Loss after 34300 iteration: 1.05691111088\n",
      "Loss after 34400 iteration: 0.877793908119\n",
      "Loss after 34500 iteration: 0.7764518857\n",
      "Loss after 34600 iteration: 1.70884048939\n",
      "Loss after 34700 iteration: 2.20959734917\n",
      "Loss after 34800 iteration: 0.903108298779\n",
      "Loss after 34900 iteration: 2.01516151428\n",
      "Loss after 35000 iteration: 0.937814176083\n",
      "Loss after 35100 iteration: 1.11771976948\n",
      "Loss after 35200 iteration: 1.17074263096\n",
      "Loss after 35300 iteration: 1.99596679211\n",
      "Loss after 35400 iteration: 1.38150894642\n",
      "Loss after 35500 iteration: 0.550234496593\n",
      "Loss after 35600 iteration: 0.885800540447\n",
      "Loss after 35700 iteration: 0.796139776707\n",
      "Loss after 35800 iteration: 1.70519816875\n",
      "Loss after 35900 iteration: 1.32828223705\n",
      "Loss after 36000 iteration: 0.685065448284\n",
      "Loss after 36100 iteration: 1.01612949371\n",
      "Loss after 36200 iteration: 0.824795901775\n",
      "Loss after 36300 iteration: 1.50713658333\n",
      "Loss after 36400 iteration: 1.46253228188\n",
      "Loss after 36500 iteration: 11.4797649384\n",
      "Loss after 36600 iteration: 6833.72998047\n",
      "Loss after 36700 iteration: 39.4188728333\n",
      "Loss after 36800 iteration: 20.8287067413\n",
      "Loss after 36900 iteration: 982.91619873\n",
      "Loss after 37000 iteration: 1.69339358807\n",
      "Loss after 37100 iteration: 0.959506869316\n",
      "Loss after 37200 iteration: 1.77023530006\n",
      "Loss after 37300 iteration: 1.37281477451\n",
      "Loss after 37400 iteration: 1.09002661705\n",
      "Loss after 37500 iteration: 1.33391034603\n",
      "Loss after 37600 iteration: 0.859936594963\n",
      "Loss after 37700 iteration: 6.74404430389\n",
      "Loss after 37800 iteration: 1.00300467014\n",
      "Loss after 37900 iteration: 2.01584172249\n",
      "Loss after 38000 iteration: 1.71283876896\n",
      "Loss after 38100 iteration: 1.65451180935\n",
      "Loss after 38200 iteration: 0.802574396133\n",
      "Loss after 38300 iteration: 1.29109525681\n",
      "Loss after 38400 iteration: 0.84767639637\n",
      "Loss after 38500 iteration: 1.25768637657\n",
      "Loss after 38600 iteration: 0.809262633324\n",
      "Loss after 38700 iteration: 1.01330506802\n",
      "Loss after 38800 iteration: 0.770051658154\n",
      "Loss after 38900 iteration: 0.854137063026\n",
      "Loss after 39000 iteration: 1.13740587234\n",
      "Loss after 39100 iteration: 2.09609532356\n",
      "Loss after 39200 iteration: 2.18342137337\n",
      "Loss after 39300 iteration: 0.958895504475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 39400 iteration: 0.696436285973\n",
      "Loss after 39500 iteration: 1.85825920105\n",
      "Loss after 39600 iteration: 1.90996527672\n",
      "Loss after 39700 iteration: 1.71395981312\n",
      "Loss after 39800 iteration: 2.49350261688\n",
      "Loss after 39900 iteration: 1.02014088631\n",
      "Loss after 40000 iteration: 0.493102103472\n",
      "Loss after 40100 iteration: 1.55933344364\n",
      "Loss after 40200 iteration: 1.52543306351\n",
      "Loss after 40300 iteration: 0.47427636385\n",
      "Loss after 40400 iteration: 1.11967384815\n",
      "Loss after 40500 iteration: 0.643781244755\n",
      "Loss after 40600 iteration: 0.690904438496\n",
      "Loss after 40700 iteration: 0.89929163456\n",
      "Loss after 40800 iteration: 0.702994942665\n",
      "Loss after 40900 iteration: 0.897388696671\n",
      "Loss after 41000 iteration: 1.16950154305\n",
      "Loss after 41100 iteration: 0.955654263496\n",
      "Loss after 41200 iteration: 1.59797108173\n",
      "Loss after 41300 iteration: 0.629818320274\n",
      "Loss after 41400 iteration: 1.83480978012\n",
      "Loss after 41500 iteration: 0.893944501877\n",
      "Loss after 41600 iteration: 1.59233236313\n",
      "Loss after 41700 iteration: 0.811532735825\n",
      "Loss after 41800 iteration: 0.706308066845\n",
      "Loss after 41900 iteration: 1.06518065929\n",
      "Loss after 42000 iteration: 0.705939352512\n",
      "Loss after 42100 iteration: 0.71361041069\n",
      "Loss after 42200 iteration: 1.05904638767\n",
      "Loss after 42300 iteration: 29481.5917969\n",
      "Loss after 42400 iteration: 35406.7109375\n",
      "Loss after 42500 iteration: 37860.2421875\n",
      "Loss after 42600 iteration: 39141.9648438\n",
      "Loss after 42700 iteration: 28385.4023438\n",
      "Loss after 42800 iteration: 13940.3603516\n",
      "Loss after 42900 iteration: 13748.0458984\n",
      "Loss after 43000 iteration: 14551.6103516\n",
      "Loss after 43100 iteration: 1.12972009182\n",
      "Loss after 43200 iteration: 4762.42919922\n",
      "Loss after 43300 iteration: 4739.21386719\n",
      "Loss after 43400 iteration: 1.72898757458\n",
      "Loss after 43500 iteration: 1.001557827\n",
      "Loss after 43600 iteration: 4550.12353516\n",
      "Loss after 43700 iteration: 1.10085499287\n",
      "Loss after 43800 iteration: 0.680836379528\n",
      "Loss after 43900 iteration: 4534.88720703\n",
      "Loss after 44000 iteration: 0.724162817001\n",
      "Loss after 44100 iteration: 0.575759470463\n",
      "Loss after 44200 iteration: 1.33881700039\n",
      "Loss after 44300 iteration: 0.854634404182\n",
      "Loss after 44400 iteration: 31037.0859375\n",
      "Loss after 44500 iteration: 70368.1953125\n",
      "Loss after 44600 iteration: 34412.8007812\n",
      "Loss after 44700 iteration: 22259.2207031\n",
      "Loss after 44800 iteration: 9883.08007812\n",
      "Loss after 44900 iteration: 6329.15820312\n",
      "Loss after 45000 iteration: 18692.5390625\n",
      "Loss after 45100 iteration: 3077.01489258\n",
      "Loss after 45200 iteration: 3053.03564453\n",
      "Loss after 45300 iteration: 3034.4609375\n",
      "Loss after 45400 iteration: 1.62916409969\n",
      "Loss after 45500 iteration: 3008.35009766\n",
      "Loss after 45600 iteration: 0.860716640949\n",
      "Loss after 45700 iteration: 2912.55541992\n",
      "Loss after 45800 iteration: 1.40100634098\n",
      "Loss after 45900 iteration: 1.17366480827\n",
      "Loss after 46000 iteration: 1.72524750233\n",
      "Loss after 46100 iteration: 2675.67211914\n",
      "Loss after 46200 iteration: 1.7398378849\n",
      "Loss after 46300 iteration: 24906.8203125\n",
      "Loss after 46400 iteration: 13914.2978516\n",
      "Loss after 46500 iteration: 19893.4550781\n",
      "Loss after 46600 iteration: 15914.8310547\n",
      "Loss after 46700 iteration: 5166.09619141\n",
      "Loss after 46800 iteration: 10125.8212891\n",
      "Loss after 46900 iteration: 2493.24438477\n",
      "Loss after 47000 iteration: 0.715953230858\n",
      "Loss after 47100 iteration: 2321.12182617\n",
      "Loss after 47200 iteration: 2305.69848633\n",
      "Loss after 47300 iteration: 2313.20996094\n",
      "Loss after 47400 iteration: 12650.2207031\n",
      "Loss after 47500 iteration: 20406.4296875\n",
      "Loss after 47600 iteration: 28917.7148438\n",
      "Loss after 47700 iteration: 29475.6542969\n",
      "Loss after 47800 iteration: 8835.60742188\n",
      "Loss after 47900 iteration: 16999.6601562\n",
      "Loss after 48000 iteration: 6884.06201172\n",
      "Loss after 48100 iteration: 15598.3613281\n",
      "Loss after 48200 iteration: 21047.5117188\n",
      "Loss after 48300 iteration: 21206.4746094\n",
      "Loss after 48400 iteration: 14072.3769531\n",
      "Loss after 48500 iteration: 6931.30224609\n",
      "Loss after 48600 iteration: 4495.46289062\n",
      "Loss after 48700 iteration: 3311.54736328\n",
      "Loss after 48800 iteration: 3264.26220703\n",
      "Loss after 48900 iteration: 1992.25708008\n",
      "Loss after 49000 iteration: 1.76162695885\n",
      "Loss after 49100 iteration: 2862.9284668\n",
      "Loss after 49200 iteration: 1.4886264801\n",
      "Loss after 49300 iteration: 2.37961053848\n",
      "Loss after 49400 iteration: 1.10489451885\n",
      "Loss after 49500 iteration: 0.734194219112\n",
      "Loss after 49600 iteration: 2811.70581055\n",
      "Loss after 49700 iteration: 8929.99121094\n",
      "Loss after 49800 iteration: 10610.1708984\n",
      "Loss after 49900 iteration: 7226.62939453\n",
      "Loss after 50000 iteration: 3390.49584961\n",
      "Loss after 50100 iteration: 3690.14038086\n",
      "Loss after 50200 iteration: 1193.49230957\n",
      "Loss after 50300 iteration: 2367.48852539\n",
      "Loss after 50400 iteration: 572.692810059\n",
      "Loss after 50500 iteration: 4.15491533279\n",
      "Loss after 50600 iteration: 6743.43261719\n",
      "Loss after 50700 iteration: 4226.70019531\n",
      "Loss after 50800 iteration: 2695.69677734\n",
      "Loss after 50900 iteration: 1714.33044434\n",
      "Loss after 51000 iteration: 2073.35668945\n",
      "Loss after 51100 iteration: 2828.85327148\n",
      "Loss after 51200 iteration: 1581.91247559\n",
      "Loss after 51300 iteration: 1167.28173828\n",
      "Loss after 51400 iteration: 384.92401123\n",
      "Loss after 51500 iteration: 382.416595459\n",
      "Loss after 51600 iteration: 379.355102539\n",
      "Loss after 51700 iteration: 3.62226843834\n",
      "Loss after 51800 iteration: 375.687133789\n",
      "Loss after 51900 iteration: 1.42621040344\n",
      "Loss after 52000 iteration: 2.34731149673\n",
      "Loss after 52100 iteration: 373.252441406\n",
      "Loss after 52200 iteration: 1.57999312878\n",
      "Loss after 52300 iteration: 355.072235107\n",
      "Loss after 52400 iteration: 2.7492852211\n",
      "Loss after 52500 iteration: 1.86009335518\n",
      "Loss after 52600 iteration: 3.84342432022\n",
      "Loss after 52700 iteration: 2.50000214577\n",
      "Loss after 52800 iteration: 2.18097567558\n",
      "Loss after 52900 iteration: 1.40726435184\n",
      "Loss after 53000 iteration: 1.65983974934\n",
      "Loss after 53100 iteration: 1.17596304417\n",
      "Loss after 53200 iteration: 0.873738348484\n",
      "Loss after 53300 iteration: 0.881012797356\n",
      "Loss after 53400 iteration: 0.662172079086\n",
      "Loss after 53500 iteration: 1.03865456581\n",
      "Loss after 53600 iteration: 1.34614634514\n",
      "Loss after 53700 iteration: 1381.40588379\n",
      "Loss after 53800 iteration: 2711.79931641\n",
      "Loss after 53900 iteration: 1341.60754395\n",
      "Loss after 54000 iteration: 957.319580078\n",
      "Loss after 54100 iteration: 869.080871582\n",
      "Loss after 54200 iteration: 237.730728149\n",
      "Loss after 54300 iteration: 44.2926368713\n",
      "Loss after 54400 iteration: 15824.5654297\n",
      "Loss after 54500 iteration: 1.48074996471\n",
      "Loss after 54600 iteration: 68.1832275391\n",
      "Loss after 54700 iteration: 65.0124740601\n",
      "Loss after 54800 iteration: 1.23444545269\n",
      "Loss after 54900 iteration: 63.0409736633\n",
      "Loss after 55000 iteration: 0.686927616596\n",
      "Loss after 55100 iteration: 0.80899733305\n",
      "Loss after 55200 iteration: 0.541478097439\n",
      "Loss after 55300 iteration: 0.430372089148\n",
      "Loss after 55400 iteration: 1.9316534996\n",
      "Loss after 55500 iteration: 1.61528909206\n",
      "Loss after 55600 iteration: 1.08169305325\n",
      "Loss after 55700 iteration: 1.07647013664\n",
      "Loss after 55800 iteration: 0.760841965675\n",
      "Loss after 55900 iteration: 0.754619598389\n",
      "Loss after 56000 iteration: 0.863610029221\n",
      "Loss after 56100 iteration: 1.97039806843\n",
      "Loss after 56200 iteration: 1.40873539448\n",
      "Loss after 56300 iteration: 2.11085391045\n",
      "Loss after 56400 iteration: 1.59410524368\n",
      "Loss after 56500 iteration: 0.928831994534\n",
      "Loss after 56600 iteration: 2.54299616814\n",
      "Loss after 56700 iteration: 1.6130604744\n",
      "Loss after 56800 iteration: 1.52685236931\n",
      "Loss after 56900 iteration: 1.15559911728\n",
      "Loss after 57000 iteration: 0.832316160202\n",
      "Loss after 57100 iteration: 0.935565710068\n",
      "Loss after 57200 iteration: 617.22277832\n",
      "Loss after 57300 iteration: 361.98059082\n",
      "Loss after 57400 iteration: 3.11504507065\n",
      "Loss after 57500 iteration: 1.41483366489\n",
      "Loss after 57600 iteration: 142.991668701\n",
      "Loss after 57700 iteration: 2.35757946968\n",
      "Loss after 57800 iteration: 2.46579480171\n",
      "Loss after 57900 iteration: 111.117149353\n",
      "Loss after 58000 iteration: 110.005256653\n",
      "Loss after 58100 iteration: 1.85822737217\n",
      "Loss after 58200 iteration: 0.722132742405\n",
      "Loss after 58300 iteration: 1.52028381824\n",
      "Loss after 58400 iteration: 1.10969746113\n",
      "Loss after 58500 iteration: 0.361574560404\n",
      "Loss after 58600 iteration: 0.545165777206\n",
      "Loss after 58700 iteration: 1.0705370903\n",
      "Loss after 58800 iteration: 1.24385476112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 58900 iteration: 1.40390741825\n",
      "Loss after 59000 iteration: 0.896083712578\n",
      "Loss after 59100 iteration: 1.01911473274\n",
      "Loss after 59200 iteration: 0.93811160326\n",
      "Loss after 59300 iteration: 1.54628992081\n",
      "Loss after 59400 iteration: 1.52103376389\n",
      "Loss after 59500 iteration: 0.974042892456\n",
      "Loss after 59600 iteration: 1.69408357143\n",
      "Loss after 59700 iteration: 0.631433486938\n",
      "Loss after 59800 iteration: 0.73981654644\n",
      "Loss after 59900 iteration: 0.919718921185\n",
      "Loss after 60000 iteration: 0.600532531738\n",
      "Loss after 60100 iteration: 1.16440665722\n",
      "Loss after 60200 iteration: 0.629459023476\n",
      "Loss after 60300 iteration: 1.16586434841\n",
      "Loss after 60400 iteration: 0.637820839882\n",
      "Loss after 60500 iteration: 1.38982212543\n",
      "Loss after 60600 iteration: 2.35700082779\n",
      "Loss after 60700 iteration: 75.4774856567\n",
      "Loss after 60800 iteration: 23.955450058\n",
      "Loss after 60900 iteration: 74.2437210083\n",
      "Loss after 61000 iteration: 7.21956014633\n",
      "Loss after 61100 iteration: 10.1400957108\n",
      "Loss after 61200 iteration: 2.06240868568\n",
      "Loss after 61300 iteration: 3.99822545052\n",
      "Loss after 61400 iteration: 1.31361341476\n",
      "Loss after 61500 iteration: 12.0176448822\n",
      "Loss after 61600 iteration: 1.52770638466\n",
      "Loss after 61700 iteration: 2.1388323307\n",
      "Loss after 61800 iteration: 3.01312208176\n",
      "Loss after 61900 iteration: 3.16170978546\n",
      "Loss after 62000 iteration: 2.54881644249\n",
      "Loss after 62100 iteration: 1.98382818699\n",
      "Loss after 62200 iteration: 1.53118920326\n",
      "Loss after 62300 iteration: 2.55513715744\n",
      "Loss after 62400 iteration: 2.05292987823\n",
      "Loss after 62500 iteration: 1.31653940678\n",
      "Loss after 62600 iteration: 0.822245359421\n",
      "Loss after 62700 iteration: 0.954500317574\n",
      "Loss after 62800 iteration: 2.79288959503\n",
      "Loss after 62900 iteration: 1.3626075983\n",
      "Loss after 63000 iteration: 1.43120491505\n",
      "Loss after 63100 iteration: 0.496433258057\n",
      "Loss after 63200 iteration: 1.0331543684\n",
      "Loss after 63300 iteration: 1.51902699471\n",
      "Loss after 63400 iteration: 1.78289282322\n",
      "Loss after 63500 iteration: 1.21027481556\n",
      "Loss after 63600 iteration: 2.30573296547\n",
      "Loss after 63700 iteration: 1.02160465717\n",
      "Loss after 63800 iteration: 1.57144606113\n",
      "Loss after 63900 iteration: 0.9780600667\n",
      "Loss after 64000 iteration: 1.04464387894\n",
      "Loss after 64100 iteration: 1.05287468433\n",
      "Loss after 64200 iteration: 1.05529034138\n",
      "Loss after 64300 iteration: 0.480046391487\n",
      "Loss after 64400 iteration: 1.36410093307\n",
      "Loss after 64500 iteration: 1.71615850925\n",
      "Loss after 64600 iteration: 0.530840873718\n",
      "Loss after 64700 iteration: 0.595591127872\n",
      "Loss after 64800 iteration: 1.36111557484\n",
      "Loss after 64900 iteration: 1.00980508327\n",
      "Loss after 65000 iteration: 5.65545082092\n",
      "Loss after 65100 iteration: 2507.85571289\n",
      "Loss after 65200 iteration: 10319.8691406\n",
      "Loss after 65300 iteration: 1.79996275902\n",
      "Loss after 65400 iteration: 8.22050666809\n",
      "Loss after 65500 iteration: 9.82678222656\n",
      "Loss after 65600 iteration: 2145.3425293\n",
      "Loss after 65700 iteration: 1.33929085732\n",
      "Loss after 65800 iteration: 0.820548653603\n",
      "Loss after 65900 iteration: 0.882165133953\n",
      "Loss after 66000 iteration: 0.981190860271\n",
      "Loss after 66100 iteration: 2.55174255371\n",
      "Loss after 66200 iteration: 0.698703467846\n",
      "Loss after 66300 iteration: 0.686598420143\n",
      "Loss after 66400 iteration: 0.483913302422\n",
      "Loss after 66500 iteration: 0.675792455673\n",
      "Loss after 66600 iteration: 1.27806472778\n",
      "Loss after 66700 iteration: 2.10989379883\n",
      "Loss after 66800 iteration: 2.30569672585\n",
      "Loss after 66900 iteration: 1.27295053005\n",
      "Loss after 67000 iteration: 0.835373938084\n",
      "Loss after 67100 iteration: 0.916954278946\n",
      "Loss after 67200 iteration: 1.87321162224\n",
      "Loss after 67300 iteration: 1.20845413208\n",
      "Loss after 67400 iteration: 1.93239319324\n",
      "Loss after 67500 iteration: 1.49757385254\n",
      "Loss after 67600 iteration: 1.46667349339\n",
      "Loss after 67700 iteration: 1.15132534504\n",
      "Loss after 67800 iteration: 1.55898106098\n",
      "Loss after 67900 iteration: 0.9968059659\n",
      "Loss after 68000 iteration: 1.77100968361\n",
      "Loss after 68100 iteration: 1.07657659054\n",
      "Loss after 68200 iteration: 1.69780659676\n",
      "Loss after 68300 iteration: 1.35384953022\n",
      "Loss after 68400 iteration: 1.30622732639\n",
      "Loss after 68500 iteration: 0.536570608616\n",
      "Loss after 68600 iteration: 1.03159296513\n",
      "Loss after 68700 iteration: 0.941001117229\n",
      "Loss after 68800 iteration: 1.30238568783\n",
      "Loss after 68900 iteration: 1.53433489799\n",
      "Loss after 69000 iteration: 1.61569464207\n",
      "Loss after 69100 iteration: 2.02122855186\n",
      "Loss after 69200 iteration: 1.24345266819\n",
      "Loss after 69300 iteration: 0.516169428825\n",
      "Loss after 69400 iteration: 1.1118670702\n",
      "Loss after 69500 iteration: 2.36226034164\n",
      "Loss after 69600 iteration: 1.64543068409\n",
      "Loss after 69700 iteration: 0.866367936134\n",
      "Loss after 69800 iteration: 1.2008023262\n",
      "Loss after 69900 iteration: 0.342814564705\n",
      "Loss after 70000 iteration: 1.85017776489\n",
      "Loss after 70100 iteration: 0.642709672451\n",
      "Loss after 70200 iteration: 1.2632522583\n",
      "Loss after 70300 iteration: 1.27308619022\n",
      "Loss after 70400 iteration: 0.683425962925\n",
      "Loss after 70500 iteration: 1.69049465656\n",
      "Loss after 70600 iteration: 0.854763329029\n",
      "Loss after 70700 iteration: 1.10417127609\n",
      "Loss after 70800 iteration: 0.624650299549\n",
      "Loss after 70900 iteration: 6130.54541016\n",
      "Loss after 71000 iteration: 4270.32519531\n",
      "Loss after 71100 iteration: 5987.04248047\n",
      "Loss after 71200 iteration: 1408.82763672\n",
      "Loss after 71300 iteration: 1600.27392578\n",
      "Loss after 71400 iteration: 1157.42443848\n",
      "Loss after 71500 iteration: 1113.36791992\n",
      "Loss after 71600 iteration: 1.79191040993\n",
      "Loss after 71700 iteration: 1.93284416199\n",
      "Loss after 71800 iteration: 669.186218262\n",
      "Loss after 71900 iteration: 3.13651633263\n",
      "Loss after 72000 iteration: 272.820892334\n",
      "Loss after 72100 iteration: 273.025512695\n",
      "Loss after 72200 iteration: 538.80291748\n",
      "Loss after 72300 iteration: 1.1015150547\n",
      "Loss after 72400 iteration: 0.535070955753\n",
      "Loss after 72500 iteration: 2.01776218414\n",
      "Loss after 72600 iteration: 2.13635706902\n",
      "Loss after 72700 iteration: 2.16720533371\n",
      "Loss after 72800 iteration: 1.57550156116\n",
      "Loss after 72900 iteration: 371.231414795\n",
      "Loss after 73000 iteration: 1965.93359375\n",
      "Loss after 73100 iteration: 893.322875977\n",
      "Loss after 73200 iteration: 722.439331055\n",
      "Loss after 73300 iteration: 479.468261719\n",
      "Loss after 73400 iteration: 131.184890747\n",
      "Loss after 73500 iteration: 59.4780769348\n",
      "Loss after 73600 iteration: 111.029510498\n",
      "Loss after 73700 iteration: 53.1962928772\n",
      "Loss after 73800 iteration: 78.7914505005\n",
      "Loss after 73900 iteration: 1.93147051334\n",
      "Loss after 74000 iteration: 3.87255525589\n",
      "Loss after 74100 iteration: 1.37496948242\n",
      "Loss after 74200 iteration: 1.39492189884\n",
      "Loss after 74300 iteration: 32.2923927307\n",
      "Loss after 74400 iteration: 1.12515103817\n",
      "Loss after 74500 iteration: 1.57235372066\n",
      "Loss after 74600 iteration: 20.5458297729\n",
      "Loss after 74700 iteration: 0.903595805168\n",
      "Loss after 74800 iteration: 96.3494491577\n",
      "Loss after 74900 iteration: 196.697494507\n",
      "Loss after 75000 iteration: 20.7098903656\n",
      "Loss after 75100 iteration: 13.9221477509\n",
      "Loss after 75200 iteration: 15.2012376785\n",
      "Loss after 75300 iteration: 12.5915813446\n",
      "Loss after 75400 iteration: 2.7581551075\n",
      "Loss after 75500 iteration: 4.59430408478\n",
      "Loss after 75600 iteration: 3.06755566597\n",
      "Loss after 75700 iteration: 2.50693655014\n",
      "Loss after 75800 iteration: 1.35459136963\n",
      "Loss after 75900 iteration: 2.00690555573\n",
      "Loss after 76000 iteration: 27.5449924469\n",
      "Loss after 76100 iteration: 11.359087944\n",
      "Loss after 76200 iteration: 32.4328689575\n",
      "Loss after 76300 iteration: 2.18060517311\n",
      "Loss after 76400 iteration: 2.84915089607\n",
      "Loss after 76500 iteration: 3.68455243111\n",
      "Loss after 76600 iteration: 23.2765083313\n",
      "Loss after 76700 iteration: 29.3385620117\n",
      "Loss after 76800 iteration: 5.77628421783\n",
      "Loss after 76900 iteration: 6.01417636871\n",
      "Loss after 77000 iteration: 3.95953512192\n",
      "Loss after 77100 iteration: 1.90753734112\n",
      "Loss after 77200 iteration: 2.14983820915\n",
      "Loss after 77300 iteration: 2.75021958351\n",
      "Loss after 77400 iteration: 3.56126260757\n",
      "Loss after 77500 iteration: 19667.7949219\n",
      "Loss after 77600 iteration: 1.70276629925\n",
      "Loss after 77700 iteration: 1.48308098316\n",
      "Loss after 77800 iteration: 1.36424565315\n",
      "Loss after 77900 iteration: 0.968633711338\n",
      "Loss after 78000 iteration: 1.24598908424\n",
      "Loss after 78100 iteration: 16.5274715424\n",
      "Loss after 78200 iteration: 3.9367544651\n",
      "Loss after 78300 iteration: 3.89799356461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 78400 iteration: 90.6154937744\n",
      "Loss after 78500 iteration: 40.6277427673\n",
      "Loss after 78600 iteration: 3.02304625511\n",
      "Loss after 78700 iteration: 1.74836301804\n",
      "Loss after 78800 iteration: 15.4875097275\n",
      "Loss after 78900 iteration: 1.72419679165\n",
      "Loss after 79000 iteration: 1.818328619\n",
      "Loss after 79100 iteration: 62.9749984741\n",
      "Loss after 79200 iteration: 173.370803833\n",
      "Loss after 79300 iteration: 22.6094760895\n",
      "Loss after 79400 iteration: 11.7013368607\n",
      "Loss after 79500 iteration: 3.47280526161\n",
      "Loss after 79600 iteration: 5.92175483704\n",
      "Loss after 79700 iteration: 2.34692645073\n",
      "Loss after 79800 iteration: 21.9512958527\n",
      "Loss after 79900 iteration: 1.73233950138\n",
      "Loss after 80000 iteration: 15.9480857849\n",
      "Loss after 80100 iteration: 2.04672837257\n",
      "Loss after 80200 iteration: 0.974632561207\n",
      "Loss after 80300 iteration: 2.7858235836\n",
      "Loss after 80400 iteration: 1.75625991821\n",
      "Loss after 80500 iteration: 1.16160941124\n",
      "Loss after 80600 iteration: 1.54676103592\n",
      "Loss after 80700 iteration: 0.776934444904\n",
      "Loss after 80800 iteration: 0.956838071346\n",
      "Loss after 80900 iteration: 1.88770413399\n",
      "Loss after 81000 iteration: 3.18925118446\n",
      "Loss after 81100 iteration: 2.27277064323\n",
      "Loss after 81200 iteration: 2.15496206284\n",
      "Loss after 81300 iteration: 1.89549124241\n",
      "Loss after 81400 iteration: 2.65535593033\n",
      "Loss after 81500 iteration: 0.839070737362\n",
      "Loss after 81600 iteration: 1.60186815262\n",
      "Loss after 81700 iteration: 1.13866889477\n",
      "Loss after 81800 iteration: 0.765883743763\n",
      "Loss after 81900 iteration: 0.615268588066\n",
      "Loss after 82000 iteration: 0.446137160063\n",
      "Loss after 82100 iteration: 0.914706528187\n",
      "Loss after 82200 iteration: 170.441223145\n",
      "Loss after 82300 iteration: 39.9331512451\n",
      "Loss after 82400 iteration: 15.2468624115\n",
      "Loss after 82500 iteration: 16.3483848572\n",
      "Loss after 82600 iteration: 7.61774682999\n",
      "Loss after 82700 iteration: 21.5075111389\n",
      "Loss after 82800 iteration: 4.27140903473\n",
      "Loss after 82900 iteration: 2.24332928658\n",
      "Loss after 83000 iteration: 4.41261005402\n",
      "Loss after 83100 iteration: 2.22247672081\n",
      "Loss after 83200 iteration: 1.99505877495\n",
      "Loss after 83300 iteration: 1.1316202879\n",
      "Loss after 83400 iteration: 0.892086148262\n",
      "Loss after 83500 iteration: 0.965141177177\n",
      "Loss after 83600 iteration: 0.711956977844\n",
      "Loss after 83700 iteration: 1.00890088081\n",
      "Loss after 83800 iteration: 1.47389936447\n",
      "Loss after 83900 iteration: 1.9044162035\n",
      "Loss after 84000 iteration: 3.08891129494\n",
      "Loss after 84100 iteration: 2.77724766731\n",
      "Loss after 84200 iteration: 1.47812139988\n",
      "Loss after 84300 iteration: 1.72527897358\n",
      "Loss after 84400 iteration: 0.964868783951\n",
      "Loss after 84500 iteration: 1.96676182747\n",
      "Loss after 84600 iteration: 0.976022720337\n",
      "Loss after 84700 iteration: 2.1491060257\n",
      "Loss after 84800 iteration: 1.62105560303\n",
      "Loss after 84900 iteration: 2.95863819122\n",
      "Loss after 85000 iteration: 0.982729077339\n",
      "Loss after 85100 iteration: 1.67148625851\n",
      "Loss after 85200 iteration: 1.19748473167\n",
      "Loss after 85300 iteration: 1.74483275414\n",
      "Loss after 85400 iteration: 1.6752358675\n",
      "Loss after 85500 iteration: 1.23727881908\n",
      "Loss after 85600 iteration: 1.42544019222\n",
      "Loss after 85700 iteration: 112.213088989\n",
      "Loss after 85800 iteration: 223.663024902\n",
      "Loss after 85900 iteration: 125.995483398\n",
      "Loss after 86000 iteration: 55.7190666199\n",
      "Loss after 86100 iteration: 1.21477329731\n",
      "Loss after 86200 iteration: 43.0555305481\n",
      "Loss after 86300 iteration: 81.2653808594\n",
      "Loss after 86400 iteration: 40.3289375305\n",
      "Loss after 86500 iteration: 37.7403488159\n",
      "Loss after 86600 iteration: 1.02477145195\n",
      "Loss after 86700 iteration: 1.38771772385\n",
      "Loss after 86800 iteration: 1.30385780334\n",
      "Loss after 86900 iteration: 35.741569519\n",
      "Loss after 87000 iteration: 0.756558120251\n",
      "Loss after 87100 iteration: 1.27588546276\n",
      "Loss after 87200 iteration: 0.831999480724\n",
      "Loss after 87300 iteration: 1.05401599407\n",
      "Loss after 87400 iteration: 1.85410559177\n",
      "Loss after 87500 iteration: 0.803650915623\n",
      "Loss after 87600 iteration: 0.807486772537\n",
      "Loss after 87700 iteration: 1.96663427353\n",
      "Loss after 87800 iteration: 0.654024422169\n",
      "Loss after 87900 iteration: 0.560178697109\n",
      "Loss after 88000 iteration: 0.879468381405\n",
      "Loss after 88100 iteration: 0.441726773977\n",
      "Loss after 88200 iteration: 0.755729794502\n",
      "Loss after 88300 iteration: 0.98846322298\n",
      "Loss after 88400 iteration: 1.50985956192\n",
      "Loss after 88500 iteration: 0.677642762661\n",
      "Loss after 88600 iteration: 0.515463352203\n",
      "Loss after 88700 iteration: 0.721119940281\n",
      "Loss after 88800 iteration: 0.801765561104\n",
      "Loss after 88900 iteration: 0.495557278395\n",
      "Loss after 89000 iteration: 0.868550419807\n",
      "Loss after 89100 iteration: 1.17790675163\n",
      "Loss after 89200 iteration: 80.1614608765\n",
      "Loss after 89300 iteration: 5335.6171875\n",
      "Loss after 89400 iteration: 12.5742578506\n",
      "Loss after 89500 iteration: 13.5081672668\n",
      "Loss after 89600 iteration: 13.7830915451\n",
      "Loss after 89700 iteration: 27.0438232422\n",
      "Loss after 89800 iteration: 17.0152053833\n",
      "Loss after 89900 iteration: 19.0944652557\n",
      "Loss after 90000 iteration: 28.1527729034\n",
      "Loss after 90100 iteration: 2.2262403965\n",
      "Loss after 90200 iteration: 1.68679761887\n",
      "Loss after 90300 iteration: 2.36678218842\n",
      "Loss after 90400 iteration: 2.39694309235\n",
      "Loss after 90500 iteration: 2.41463303566\n",
      "Loss after 90600 iteration: 1.7224060297\n",
      "Loss after 90700 iteration: 7.40594911575\n",
      "Loss after 90800 iteration: 2.3386080265\n",
      "Loss after 90900 iteration: 1.06521689892\n",
      "Loss after 91000 iteration: 1.08045911789\n",
      "Loss after 91100 iteration: 2.75184011459\n",
      "Loss after 91200 iteration: 1.19000828266\n",
      "Loss after 91300 iteration: 1.57628560066\n",
      "Loss after 91400 iteration: 1.2346624136\n",
      "Loss after 91500 iteration: 0.885506570339\n",
      "Loss after 91600 iteration: 1.1728386879\n",
      "Loss after 91700 iteration: 0.518335998058\n",
      "Loss after 91800 iteration: 1.23298990726\n",
      "Loss after 91900 iteration: 0.709224820137\n",
      "Loss after 92000 iteration: 1.19007241726\n",
      "Loss after 92100 iteration: 1.62992966175\n",
      "Loss after 92200 iteration: 1.89669442177\n",
      "Loss after 92300 iteration: 1.58480000496\n",
      "Loss after 92400 iteration: 1.07266116142\n",
      "Loss after 92500 iteration: 1.24926996231\n",
      "Loss after 92600 iteration: 2.08270335197\n",
      "Loss after 92700 iteration: 1.17071330547\n",
      "Loss after 92800 iteration: 1.04887509346\n",
      "Loss after 92900 iteration: 1.02718245983\n",
      "Loss after 93000 iteration: 0.924325287342\n",
      "Loss after 93100 iteration: 0.830067038536\n",
      "Loss after 93200 iteration: 0.616012871265\n",
      "Loss after 93300 iteration: 1.61299300194\n",
      "Loss after 93400 iteration: 1.28117418289\n",
      "Loss after 93500 iteration: 0.874460220337\n",
      "Loss after 93600 iteration: 68.803276062\n",
      "Loss after 93700 iteration: 4.67354440689\n",
      "Loss after 93800 iteration: 2.72601556778\n",
      "Loss after 93900 iteration: 2.43929815292\n",
      "Loss after 94000 iteration: 1.48352456093\n",
      "Loss after 94100 iteration: 1.5567317009\n",
      "Loss after 94200 iteration: 16.9012622833\n",
      "Loss after 94300 iteration: 1.61872506142\n",
      "Loss after 94400 iteration: 1.00163853168\n",
      "Loss after 94500 iteration: 12.4232444763\n",
      "Loss after 94600 iteration: 3.4178609848\n",
      "Loss after 94700 iteration: 1.46110677719\n",
      "Loss after 94800 iteration: 2.11413931847\n",
      "Loss after 94900 iteration: 0.919277071953\n",
      "Loss after 95000 iteration: 0.813530743122\n",
      "Loss after 95100 iteration: 0.565735757351\n",
      "Loss after 95200 iteration: 0.822952985764\n",
      "Loss after 95300 iteration: 1.2877676487\n",
      "Loss after 95400 iteration: 1.40899252892\n",
      "Loss after 95500 iteration: 0.686073362827\n",
      "Loss after 95600 iteration: 2.03273034096\n",
      "Loss after 95700 iteration: 1.4006524086\n",
      "Loss after 95800 iteration: 1.69236707687\n",
      "Loss after 95900 iteration: 1.7899813652\n",
      "Loss after 96000 iteration: 2.75872397423\n",
      "Loss after 96100 iteration: 1.48608624935\n",
      "Loss after 96200 iteration: 1.7402125597\n",
      "Loss after 96300 iteration: 1.56637966633\n",
      "Loss after 96400 iteration: 0.579946100712\n",
      "Loss after 96500 iteration: 1.8581032753\n",
      "Loss after 96600 iteration: 1.17751693726\n",
      "Loss after 96700 iteration: 1.08000922203\n",
      "Loss after 96800 iteration: 1.2521674633\n",
      "Loss after 96900 iteration: 1.01569032669\n",
      "Loss after 97000 iteration: 0.654108941555\n",
      "Loss after 97100 iteration: 1.16685760021\n",
      "Loss after 97200 iteration: 1.13114142418\n",
      "Loss after 97300 iteration: 1.16516149044\n",
      "Loss after 97400 iteration: 1.2678617239\n",
      "Loss after 97500 iteration: 1.26238572598\n",
      "Loss after 97600 iteration: 0.70917725563\n",
      "Loss after 97700 iteration: 0.76907068491\n",
      "Loss after 97800 iteration: 0.775160491467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 97900 iteration: 0.984153926373\n",
      "Loss after 98000 iteration: 1.04472482204\n",
      "Loss after 98100 iteration: 1.832203269\n",
      "Loss after 98200 iteration: 0.955803513527\n",
      "Loss after 98300 iteration: 0.303664594889\n",
      "Loss after 98400 iteration: 0.79790532589\n",
      "Loss after 98500 iteration: 1.1100076437\n",
      "Loss after 98600 iteration: 1.10985004902\n",
      "Loss after 98700 iteration: 1.44940638542\n",
      "Loss after 98800 iteration: 1.23051142693\n",
      "Loss after 98900 iteration: 0.986417651176\n",
      "Loss after 99000 iteration: 1.91396462917\n",
      "Loss after 99100 iteration: 1.05740904808\n",
      "Loss after 99200 iteration: 1.16314089298\n",
      "Loss after 99300 iteration: 0.662886083126\n",
      "Loss after 99400 iteration: 1306.22192383\n",
      "Loss after 99500 iteration: 641.718200684\n",
      "Loss after 99600 iteration: 6418.02197266\n",
      "Loss after 99700 iteration: 128.094680786\n",
      "Loss after 99800 iteration: 5.98485422134\n",
      "Loss after 99900 iteration: 68.9985046387\n",
      "Loss after 100000 iteration: 62.047706604\n",
      "Loss after 100100 iteration: 16.5018844604\n",
      "Loss after 100200 iteration: 1.67543959618\n",
      "Loss after 100300 iteration: 13.5086078644\n",
      "Loss after 100400 iteration: 1.42877805233\n",
      "Loss after 100500 iteration: 13.2574901581\n",
      "Loss after 100600 iteration: 1.02716624737\n",
      "Loss after 100700 iteration: 2.15112257004\n",
      "Loss after 100800 iteration: 1.34043729305\n",
      "Loss after 100900 iteration: 1.22916483879\n",
      "Loss after 101000 iteration: 0.748180627823\n",
      "Loss after 101100 iteration: 1.36362695694\n",
      "Loss after 101200 iteration: 1.63651072979\n",
      "Loss after 101300 iteration: 0.957264244556\n",
      "Loss after 101400 iteration: 0.81299674511\n",
      "Loss after 101500 iteration: 79.2364120483\n",
      "Loss after 101600 iteration: 33.7303962708\n",
      "Loss after 101700 iteration: 12.6180992126\n",
      "Loss after 101800 iteration: 40.5169029236\n",
      "Loss after 101900 iteration: 6.50233411789\n",
      "Loss after 102000 iteration: 32.3615570068\n",
      "Loss after 102100 iteration: 4.21026420593\n",
      "Loss after 102200 iteration: 2.67064356804\n",
      "Loss after 102300 iteration: 3.74417376518\n",
      "Loss after 102400 iteration: 1.67900335789\n",
      "Loss after 102500 iteration: 2.28883647919\n",
      "Loss after 102600 iteration: 2.13847613335\n",
      "Loss after 102700 iteration: 1.09412813187\n",
      "Loss after 102800 iteration: 1.12276053429\n",
      "Loss after 102900 iteration: 1.46488416195\n",
      "Loss after 103000 iteration: 1.36853528023\n",
      "Loss after 103100 iteration: 1.09908163548\n",
      "Loss after 103200 iteration: 1.95521581173\n",
      "Loss after 103300 iteration: 2.29979491234\n",
      "Loss after 103400 iteration: 9.99563980103\n",
      "Loss after 103500 iteration: 52.0985832214\n",
      "Loss after 103600 iteration: 1.97883558273\n",
      "Loss after 103700 iteration: 10.4023838043\n",
      "Loss after 103800 iteration: 9.10407352448\n",
      "Loss after 103900 iteration: 5.59932851791\n",
      "Loss after 104000 iteration: 2.48657345772\n",
      "Loss after 104100 iteration: 2.12271213531\n",
      "Loss after 104200 iteration: 4.00929450989\n",
      "Loss after 104300 iteration: 3.57789230347\n",
      "Loss after 104400 iteration: 4.5425696373\n",
      "Loss after 104500 iteration: 2.04905772209\n",
      "Loss after 104600 iteration: 9.27801513672\n",
      "Loss after 104700 iteration: 3.70709824562\n",
      "Loss after 104800 iteration: 3.49106454849\n",
      "Loss after 104900 iteration: 6.32526350021\n",
      "Loss after 105000 iteration: 1.0166271925\n",
      "Loss after 105100 iteration: 0.942520141602\n",
      "Loss after 105200 iteration: 2.85553431511\n",
      "Loss after 105300 iteration: 3.45156526566\n",
      "Loss after 105400 iteration: 11.4700946808\n",
      "Loss after 105500 iteration: 2245.5378418\n",
      "Loss after 105600 iteration: 11.4021539688\n",
      "Loss after 105700 iteration: 7.15024852753\n",
      "Loss after 105800 iteration: 4.46859455109\n",
      "Loss after 105900 iteration: 64.4423522949\n",
      "Loss after 106000 iteration: 1.67637944221\n",
      "Loss after 106100 iteration: 1.82873117924\n",
      "Loss after 106200 iteration: 2.45674943924\n",
      "Loss after 106300 iteration: 1.27531182766\n",
      "Loss after 106400 iteration: 3.76946568489\n",
      "Loss after 106500 iteration: 1.68735659122\n",
      "Loss after 106600 iteration: 1.0973995924\n",
      "Loss after 106700 iteration: 5694.65527344\n",
      "Loss after 106800 iteration: 3.06245946884\n",
      "Loss after 106900 iteration: 2.60849809647\n",
      "Loss after 107000 iteration: 17.6213092804\n",
      "Loss after 107100 iteration: 2.1553170681\n",
      "Loss after 107200 iteration: 2.01291418076\n",
      "Loss after 107300 iteration: 2.22908830643\n",
      "Loss after 107400 iteration: 2.97130250931\n",
      "Loss after 107500 iteration: 1.78220403194\n",
      "Loss after 107600 iteration: 2.6489803791\n",
      "Loss after 107700 iteration: 41.4362297058\n",
      "Loss after 107800 iteration: 5.4815530777\n",
      "Loss after 107900 iteration: 13067.4384766\n",
      "Loss after 108000 iteration: 2.7412314415\n",
      "Loss after 108100 iteration: 3.51679563522\n",
      "Loss after 108200 iteration: 3.18146491051\n",
      "Loss after 108300 iteration: 3.31054735184\n",
      "Loss after 108400 iteration: 1.01307106018\n",
      "Loss after 108500 iteration: 1.69733798504\n",
      "Loss after 108600 iteration: 17.0649452209\n",
      "Loss after 108700 iteration: 15.2631025314\n",
      "Loss after 108800 iteration: 1.34239447117\n",
      "Loss after 108900 iteration: 0.927348971367\n",
      "Loss after 109000 iteration: 1.57119095325\n",
      "Loss after 109100 iteration: 1.66850686073\n",
      "Loss after 109200 iteration: 1.81323981285\n",
      "Loss after 109300 iteration: 14.5227222443\n",
      "Loss after 109400 iteration: 1.43137133121\n",
      "Loss after 109500 iteration: 2.55111837387\n",
      "Loss after 109600 iteration: 3.91885995865\n",
      "Loss after 109700 iteration: 3.88847637177\n",
      "Loss after 109800 iteration: 2.22548365593\n",
      "Loss after 109900 iteration: 2.26264309883\n",
      "Loss after 110000 iteration: 1.60833096504\n",
      "Loss after 110100 iteration: 1.4462647438\n",
      "Loss after 110200 iteration: 1.82234013081\n",
      "Loss after 110300 iteration: 1.26827299595\n",
      "Loss after 110400 iteration: 0.97233325243\n",
      "Loss after 110500 iteration: 1.33640098572\n",
      "Loss after 110600 iteration: 1.54893922806\n",
      "Loss after 110700 iteration: 0.81472915411\n",
      "Loss after 110800 iteration: 127.500732422\n",
      "Loss after 110900 iteration: 18.4782238007\n",
      "Loss after 111000 iteration: 9.04759216309\n",
      "Loss after 111100 iteration: 4.45216083527\n",
      "Loss after 111200 iteration: 3.21774935722\n",
      "Loss after 111300 iteration: 3.04632878304\n",
      "Loss after 111400 iteration: 3.92503452301\n",
      "Loss after 111500 iteration: 2.24609994888\n",
      "Loss after 111600 iteration: 2.31325054169\n",
      "Loss after 111700 iteration: 2.17636728287\n",
      "Loss after 111800 iteration: 1.50893509388\n",
      "Loss after 111900 iteration: 0.968017697334\n",
      "Loss after 112000 iteration: 1.20878827572\n",
      "Loss after 112100 iteration: 1.82977342606\n",
      "Loss after 112200 iteration: 1.07429361343\n",
      "Loss after 112300 iteration: 0.769433021545\n",
      "Loss after 112400 iteration: 1.31075561047\n",
      "Loss after 112500 iteration: 1.75045025349\n",
      "Loss after 112600 iteration: 1.34742939472\n",
      "Loss after 112700 iteration: 0.909267187119\n",
      "Loss after 112800 iteration: 0.693233549595\n",
      "Loss after 112900 iteration: 0.769869208336\n",
      "Loss after 113000 iteration: 1.29429543018\n",
      "Loss after 113100 iteration: 2.10240292549\n",
      "Loss after 113200 iteration: 1.44062304497\n",
      "Loss after 113300 iteration: 1.5466272831\n",
      "Loss after 113400 iteration: 1.28650975227\n",
      "Loss after 113500 iteration: 2.26665854454\n",
      "Loss after 113600 iteration: 1.24021971226\n",
      "Loss after 113700 iteration: 2.04123330116\n",
      "Loss after 113800 iteration: 1.45428609848\n",
      "Loss after 113900 iteration: 1.74558806419\n",
      "Loss after 114000 iteration: 1.26402556896\n",
      "Loss after 114100 iteration: 1.32922518253\n",
      "Loss after 114200 iteration: 1.04911744595\n",
      "Loss after 114300 iteration: 12902.5761719\n",
      "Loss after 114400 iteration: 1.88561463356\n",
      "Loss after 114500 iteration: 2.94364142418\n",
      "Loss after 114600 iteration: 1.83112549782\n",
      "Loss after 114700 iteration: 2.54487252235\n",
      "Loss after 114800 iteration: 2.96709394455\n",
      "Loss after 114900 iteration: 4.93357515335\n",
      "Loss after 115000 iteration: 2.07835006714\n",
      "Loss after 115100 iteration: 1.31322813034\n",
      "Loss after 115200 iteration: 1.21359205246\n",
      "Loss after 115300 iteration: 1.15938055515\n",
      "Loss after 115400 iteration: 0.850239813328\n",
      "Loss after 115500 iteration: 14810.0683594\n",
      "Loss after 115600 iteration: 0.8895226717\n",
      "Loss after 115700 iteration: 0.964464306831\n",
      "Loss after 115800 iteration: 0.876236736774\n",
      "Loss after 115900 iteration: 2.04723119736\n",
      "Loss after 116000 iteration: 0.882976830006\n",
      "Loss after 116100 iteration: 0.979959130287\n",
      "Loss after 116200 iteration: 1.60597872734\n",
      "Loss after 116300 iteration: 1.15369522572\n",
      "Loss after 116400 iteration: 0.829512000084\n",
      "Loss after 116500 iteration: 0.623151421547\n",
      "Loss after 116600 iteration: 0.827034890652\n",
      "Loss after 116700 iteration: 0.875393867493\n",
      "Loss after 116800 iteration: 0.671836614609\n",
      "Loss after 116900 iteration: 1.13700282574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 117000 iteration: 1.2972189188\n",
      "Loss after 117100 iteration: 1.21840167046\n",
      "Loss after 117200 iteration: 0.892256319523\n",
      "Loss after 117300 iteration: 1.48539328575\n",
      "Loss after 117400 iteration: 0.982440650463\n",
      "Loss after 117500 iteration: 0.438115686178\n",
      "Loss after 117600 iteration: 1.42187726498\n",
      "Loss after 117700 iteration: 1.39330112934\n",
      "Loss after 117800 iteration: 35.1770248413\n",
      "Loss after 117900 iteration: 5.81013393402\n",
      "Loss after 118000 iteration: 7.36690044403\n",
      "Loss after 118100 iteration: 1.79558765888\n",
      "Loss after 118200 iteration: 2.09813928604\n",
      "Loss after 118300 iteration: 1.44370901585\n",
      "Loss after 118400 iteration: 0.716563642025\n",
      "Loss after 118500 iteration: 11.708855629\n",
      "Loss after 118600 iteration: 5.62614870071\n",
      "Loss after 118700 iteration: 2.67799282074\n",
      "Loss after 118800 iteration: 2.05282402039\n",
      "Loss after 118900 iteration: 1.85617208481\n",
      "Loss after 119000 iteration: 3.63927054405\n",
      "Loss after 119100 iteration: 2.61839175224\n",
      "Loss after 119200 iteration: 2.08677721024\n",
      "Loss after 119300 iteration: 3.37800240517\n",
      "Loss after 119400 iteration: 3.07316923141\n",
      "Loss after 119500 iteration: 1.66817891598\n",
      "Loss after 119600 iteration: 1.21126663685\n",
      "Loss after 119700 iteration: 1.45121562481\n",
      "Loss after 119800 iteration: 0.93998503685\n",
      "Loss after 119900 iteration: 0.927139222622\n",
      "Loss after 120000 iteration: 0.826387345791\n",
      "Loss after 120100 iteration: 0.976920962334\n",
      "Loss after 120200 iteration: 1.46055710316\n",
      "Loss after 120300 iteration: 1.40154910088\n",
      "Loss after 120400 iteration: 1.31921029091\n",
      "Loss after 120500 iteration: 1.48715531826\n",
      "Loss after 120600 iteration: 2.04050993919\n",
      "Loss after 120700 iteration: 1.17300724983\n",
      "Loss after 120800 iteration: 0.344573646784\n",
      "Loss after 120900 iteration: 1.41793227196\n",
      "Loss after 121000 iteration: 1.00900053978\n",
      "Loss after 121100 iteration: 1.06158792973\n",
      "Loss after 121200 iteration: 1.3664162159\n",
      "Loss after 121300 iteration: 0.913700461388\n",
      "Loss after 121400 iteration: 1.03612411022\n",
      "Loss after 121500 iteration: 1.38352131844\n",
      "Loss after 121600 iteration: 0.73849272728\n",
      "Loss after 121700 iteration: 1.21213018894\n",
      "Loss after 121800 iteration: 0.519279241562\n",
      "Loss after 121900 iteration: 1.25949430466\n",
      "Loss after 122000 iteration: 0.784338057041\n",
      "Loss after 122100 iteration: 0.809408962727\n",
      "Loss after 122200 iteration: 21.1437282562\n",
      "Loss after 122300 iteration: 871.152893066\n",
      "Loss after 122400 iteration: 14.6025133133\n",
      "Loss after 122500 iteration: 2.35141253471\n",
      "Loss after 122600 iteration: 860.667358398\n",
      "Loss after 122700 iteration: 1.75327444077\n",
      "Loss after 122800 iteration: 1.47917580605\n",
      "Loss after 122900 iteration: 1.73152112961\n",
      "Loss after 123000 iteration: 1.70548903942\n",
      "Loss after 123100 iteration: 1.10998284817\n",
      "Loss after 123200 iteration: 4.70260000229\n",
      "Loss after 123300 iteration: 6.63399267197\n",
      "Loss after 123400 iteration: 1.80426764488\n",
      "Loss after 123500 iteration: 1.20649766922\n",
      "Loss after 123600 iteration: 4.14901971817\n",
      "Loss after 123700 iteration: 3.20106506348\n",
      "Loss after 123800 iteration: 1.30443894863\n",
      "Loss after 123900 iteration: 1.63349890709\n",
      "Loss after 124000 iteration: 1.07520270348\n",
      "Loss after 124100 iteration: 0.784123361111\n",
      "Loss after 124200 iteration: 0.801425814629\n",
      "Loss after 124300 iteration: 1.61038815975\n",
      "Loss after 124400 iteration: 0.69410610199\n",
      "Loss after 124500 iteration: 1.31049370766\n",
      "Loss after 124600 iteration: 0.910540044308\n",
      "Loss after 124700 iteration: 6.74860477448\n",
      "Loss after 124800 iteration: 1.34930980206\n",
      "Loss after 124900 iteration: 1.65058851242\n",
      "Loss after 125000 iteration: 2.13346481323\n",
      "Loss after 125100 iteration: 1.01147651672\n",
      "Loss after 125200 iteration: 1.96647715569\n",
      "Loss after 125300 iteration: 1.73232007027\n",
      "Loss after 125400 iteration: 1.56542313099\n",
      "Loss after 125500 iteration: 1.21418070793\n",
      "Loss after 125600 iteration: 0.948808312416\n",
      "Loss after 125700 iteration: 1.24372410774\n",
      "Loss after 125800 iteration: 1.33823060989\n",
      "Loss after 125900 iteration: 0.613302350044\n",
      "Loss after 126000 iteration: 1.04860699177\n",
      "Loss after 126100 iteration: 1.02725434303\n",
      "Loss after 126200 iteration: 0.693852186203\n",
      "Loss after 126300 iteration: 1.81890487671\n",
      "Loss after 126400 iteration: 0.689647436142\n",
      "Loss after 126500 iteration: 1.43938851357\n",
      "Loss after 126600 iteration: 1.58393013477\n",
      "Loss after 126700 iteration: 0.741647958755\n",
      "Loss after 126800 iteration: 0.562262713909\n",
      "Loss after 126900 iteration: 0.69692838192\n",
      "Loss after 127000 iteration: 0.999949276447\n",
      "Loss after 127100 iteration: 1.26949763298\n",
      "Loss after 127200 iteration: 1.45167040825\n",
      "Loss after 127300 iteration: 0.810033679008\n",
      "Loss after 127400 iteration: 0.975219905376\n",
      "Loss after 127500 iteration: 1.04537844658\n",
      "Loss after 127600 iteration: 1.22631394863\n",
      "Loss after 127700 iteration: 1.50283634663\n",
      "Loss after 127800 iteration: 1.31382608414\n",
      "Loss after 127900 iteration: 1.10045313835\n",
      "Loss after 128000 iteration: 183.256790161\n",
      "Loss after 128100 iteration: 383.758911133\n",
      "Loss after 128200 iteration: 151.822280884\n",
      "Loss after 128300 iteration: 268.696838379\n",
      "Loss after 128400 iteration: 28.5382938385\n",
      "Loss after 128500 iteration: 4.11087560654\n",
      "Loss after 128600 iteration: 8.74146366119\n",
      "Loss after 128700 iteration: 1.92874526978\n",
      "Loss after 128800 iteration: 1.12636947632\n",
      "Loss after 128900 iteration: 1.92571258545\n",
      "Loss after 129000 iteration: 1.02481544018\n",
      "Loss after 129100 iteration: 2.86483669281\n",
      "Loss after 129200 iteration: 3.44425296783\n",
      "Loss after 129300 iteration: 0.888658285141\n",
      "Loss after 129400 iteration: 1.73427200317\n",
      "Loss after 129500 iteration: 1.52422308922\n",
      "Loss after 129600 iteration: 2.00227475166\n",
      "Loss after 129700 iteration: 2.23007369041\n",
      "Loss after 129800 iteration: 1.40164494514\n",
      "Loss after 129900 iteration: 2.25406217575\n",
      "Loss after 130000 iteration: 27.7182292938\n",
      "Loss after 130100 iteration: 21.2881393433\n",
      "Loss after 130200 iteration: 10.5471048355\n",
      "Loss after 130300 iteration: 6596.21582031\n",
      "Loss after 130400 iteration: 2.71824765205\n",
      "Loss after 130500 iteration: 3.27568364143\n",
      "Loss after 130600 iteration: 29.2252120972\n",
      "Loss after 130700 iteration: 12.8241071701\n",
      "Loss after 130800 iteration: 8.13838005066\n",
      "Loss after 130900 iteration: 9.00823402405\n",
      "Loss after 131000 iteration: 4.24600028992\n",
      "Loss after 131100 iteration: 2.22118806839\n",
      "Loss after 131200 iteration: 1.56759572029\n",
      "Loss after 131300 iteration: 2.51016139984\n",
      "Loss after 131400 iteration: 1.25974500179\n",
      "Loss after 131500 iteration: 1.9439201355\n",
      "Loss after 131600 iteration: 1.51109337807\n",
      "Loss after 131700 iteration: 1.10502481461\n",
      "Loss after 131800 iteration: 1.21631491184\n",
      "Loss after 131900 iteration: 35.1169891357\n",
      "Loss after 132000 iteration: 3.39966034889\n",
      "Loss after 132100 iteration: 59.2577056885\n",
      "Loss after 132200 iteration: 19575.9179688\n",
      "Loss after 132300 iteration: 9.48421764374\n",
      "Loss after 132400 iteration: 17.3945922852\n",
      "Loss after 132500 iteration: 2.33991289139\n",
      "Loss after 132600 iteration: 3.59688448906\n",
      "Loss after 132700 iteration: 4.08441495895\n",
      "Loss after 132800 iteration: 1.60014653206\n",
      "Loss after 132900 iteration: 1.57790434361\n",
      "Loss after 133000 iteration: 1.35952186584\n",
      "Loss after 133100 iteration: 12.3115968704\n",
      "Loss after 133200 iteration: 1.00539147854\n",
      "Loss after 133300 iteration: 7.05080938339\n",
      "Loss after 133400 iteration: 1.48155903816\n",
      "Loss after 133500 iteration: 2.10829615593\n",
      "Loss after 133600 iteration: 15.235168457\n",
      "Loss after 133700 iteration: 59.316493988\n",
      "Loss after 133800 iteration: 16.9135227203\n",
      "Loss after 133900 iteration: 13.5175619125\n",
      "Loss after 134000 iteration: 5.19821071625\n",
      "Loss after 134100 iteration: 18.5982627869\n",
      "Loss after 134200 iteration: 27.2242927551\n",
      "Loss after 134300 iteration: 14.2379512787\n",
      "Loss after 134400 iteration: 2.8731315136\n",
      "Loss after 134500 iteration: 1.82124221325\n",
      "Loss after 134600 iteration: 2.40363359451\n",
      "Loss after 134700 iteration: 2.1490213871\n",
      "Loss after 134800 iteration: 24.3537044525\n",
      "Loss after 134900 iteration: 1.31964957714\n",
      "Loss after 135000 iteration: 1.09797179699\n",
      "Loss after 135100 iteration: 1.68697810173\n",
      "Loss after 135200 iteration: 0.86998206377\n",
      "Loss after 135300 iteration: 2.67614626884\n",
      "Loss after 135400 iteration: 7.16570425034\n",
      "Loss after 135500 iteration: 2.76240849495\n",
      "Loss after 135600 iteration: 2.26733136177\n",
      "Loss after 135700 iteration: 1.80268073082\n",
      "Loss after 135800 iteration: 6.26728868484\n",
      "Loss after 135900 iteration: 2.16714811325\n",
      "Loss after 136000 iteration: 4.7818570137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 136100 iteration: 18.2983589172\n",
      "Loss after 136200 iteration: 22.0979328156\n",
      "Loss after 136300 iteration: 11147.8623047\n",
      "Loss after 136400 iteration: 5.3764872551\n",
      "Loss after 136500 iteration: 4343.63427734\n",
      "Loss after 136600 iteration: 5.32090044022\n",
      "Loss after 136700 iteration: 3.70740509033\n",
      "Loss after 136800 iteration: 6.37613630295\n",
      "Loss after 136900 iteration: 2.66247320175\n",
      "Loss after 137000 iteration: 0.851670444012\n",
      "Loss after 137100 iteration: 3.9883916378\n",
      "Loss after 137200 iteration: 1.29845023155\n",
      "Loss after 137300 iteration: 1.21606910229\n",
      "Loss after 137400 iteration: 2.62934470177\n",
      "Loss after 137500 iteration: 1.34270966053\n",
      "Loss after 137600 iteration: 0.939563989639\n",
      "Loss after 137700 iteration: 1.38392055035\n",
      "Loss after 137800 iteration: 1.02933037281\n",
      "Loss after 137900 iteration: 1.26337945461\n",
      "Loss after 138000 iteration: 4.28475809097\n",
      "Loss after 138100 iteration: 1.9890152216\n",
      "Loss after 138200 iteration: 0.93350225687\n",
      "Loss after 138300 iteration: 1.39536774158\n",
      "Loss after 138400 iteration: 0.870923638344\n",
      "Loss after 138500 iteration: 3.48559737206\n",
      "Loss after 138600 iteration: 1.21373522282\n",
      "Loss after 138700 iteration: 1.85951173306\n",
      "Loss after 138800 iteration: 1.28886282444\n",
      "Loss after 138900 iteration: 1.00512635708\n",
      "Loss after 139000 iteration: 1.01717579365\n",
      "Loss after 139100 iteration: 0.914285778999\n",
      "Loss after 139200 iteration: 0.906526327133\n",
      "Loss after 139300 iteration: 165.224990845\n",
      "Loss after 139400 iteration: 65.4319076538\n",
      "Loss after 139500 iteration: 33.2339668274\n",
      "Loss after 139600 iteration: 292.191986084\n",
      "Loss after 139700 iteration: 7.58435058594\n",
      "Loss after 139800 iteration: 2.70649385452\n",
      "Loss after 139900 iteration: 35.9774589539\n",
      "Loss after 140000 iteration: 2.29022169113\n",
      "Loss after 140100 iteration: 23.9825878143\n",
      "Loss after 140200 iteration: 11.0252571106\n",
      "Loss after 140300 iteration: 0.942014336586\n",
      "Loss after 140400 iteration: 1.85819816589\n",
      "Loss after 140500 iteration: 5.03932237625\n",
      "Loss after 140600 iteration: 2.63685107231\n",
      "Loss after 140700 iteration: 1.25557255745\n",
      "Loss after 140800 iteration: 0.650512158871\n",
      "Loss after 140900 iteration: 0.831291735172\n",
      "Loss after 141000 iteration: 0.895502448082\n",
      "Loss after 141100 iteration: 1.03807914257\n",
      "Loss after 141200 iteration: 1.17022120953\n",
      "Loss after 141300 iteration: 1.7224509716\n",
      "Loss after 141400 iteration: 0.748008489609\n",
      "Loss after 141500 iteration: 1.32351088524\n",
      "Loss after 141600 iteration: 0.762914121151\n",
      "Loss after 141700 iteration: 1.91116333008\n",
      "Loss after 141800 iteration: 1.31288123131\n",
      "Loss after 141900 iteration: 1.60948610306\n",
      "Loss after 142000 iteration: 0.990308761597\n",
      "Loss after 142100 iteration: 1.62253892422\n",
      "Loss after 142200 iteration: 1.63518679142\n",
      "Loss after 142300 iteration: 1.36744356155\n",
      "Loss after 142400 iteration: 1.84117555618\n",
      "Loss after 142500 iteration: 0.916491210461\n",
      "Loss after 142600 iteration: 0.702633857727\n",
      "Loss after 142700 iteration: 1.68460845947\n"
     ]
    },
    {
     "ename": "PermissionDeniedError",
     "evalue": "/ModelWeights; Permission denied\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, beta1_power, beta2_power, dense/bias, dense/bias/Adam, dense/bias/Adam_1, dense/kernel, dense/kernel/Adam, dense/kernel/Adam_1, rnn/basic_lstm_cell/bias, rnn/basic_lstm_cell/bias/Adam, rnn/basic_lstm_cell/bias/Adam_1, rnn/basic_lstm_cell/kernel, rnn/basic_lstm_cell/kernel/Adam, rnn/basic_lstm_cell/kernel/Adam_1)]]\n\nCaused by op u'save/SaveV2', defined at:\n  File \"/Users/maxime/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/maxime/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-22-f996a9bafa11>\", line 1, in <module>\n    saver = tf.train.Saver()\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1239, in __init__\n    self.build()\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1248, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1284, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 762, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 297, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 240, in save_op\n    tensors)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1174, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nPermissionDeniedError (see above for traceback): /ModelWeights; Permission denied\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, beta1_power, beta2_power, dense/bias, dense/bias/Adam, dense/bias/Adam_1, dense/kernel, dense/kernel/Adam, dense/kernel/Adam_1, rnn/basic_lstm_cell/bias, rnn/basic_lstm_cell/bias/Adam, rnn/basic_lstm_cell/bias/Adam_1, rnn/basic_lstm_cell/kernel, rnn/basic_lstm_cell/kernel/Adam, rnn/basic_lstm_cell/kernel/Adam_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f996a9bafa11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss after {} iteration: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/ModelWeights/test_model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1591\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1592\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1594\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m           self._build_eager(\n",
      "\u001b[0;32m/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: /ModelWeights; Permission denied\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, beta1_power, beta2_power, dense/bias, dense/bias/Adam, dense/bias/Adam_1, dense/kernel, dense/kernel/Adam, dense/kernel/Adam_1, rnn/basic_lstm_cell/bias, rnn/basic_lstm_cell/bias/Adam, rnn/basic_lstm_cell/bias/Adam_1, rnn/basic_lstm_cell/kernel, rnn/basic_lstm_cell/kernel/Adam, rnn/basic_lstm_cell/kernel/Adam_1)]]\n\nCaused by op u'save/SaveV2', defined at:\n  File \"/Users/maxime/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/maxime/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-22-f996a9bafa11>\", line 1, in <module>\n    saver = tf.train.Saver()\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1239, in __init__\n    self.build()\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1248, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1284, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 762, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 297, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 240, in save_op\n    tensors)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1174, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/Users/maxime/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nPermissionDeniedError (see above for traceback): /ModelWeights; Permission denied\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, beta1_power, beta2_power, dense/bias, dense/bias/Adam, dense/bias/Adam_1, dense/kernel, dense/kernel/Adam, dense/kernel/Adam_1, rnn/basic_lstm_cell/bias, rnn/basic_lstm_cell/bias/Adam, rnn/basic_lstm_cell/bias/Adam_1, rnn/basic_lstm_cell/kernel, rnn/basic_lstm_cell/kernel/Adam, rnn/basic_lstm_cell/kernel/Adam_1)]]\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        sess.run(iterator.initializer)\n",
    "        current_loss = sess.run(loss)\n",
    "        n_iteration = 0\n",
    "        print(\"Loss after {} epochs: {}\".format(epoch,current_loss))\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                _, current_loss = sess.run([training_op,loss])\n",
    "                n_iteration += 1\n",
    "                \n",
    "                if not(n_iteration%100):\n",
    "                    print(\"Loss after {} iteration: {}\".format(n_iteration,current_loss)) \n",
    "            except tf.errors.OutOfRangeError:\n",
    "                saver.save(sess, \"/ModelWeights/test_model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat = loadmat(train_addrs[0])\n",
    "features = list(mat['structarr'][0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_base = features[28].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spike_raster_base"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
